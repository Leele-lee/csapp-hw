# 12.20

> Consider a simpler variant of the readers-writers problem where there are at most N readers. Derive a solution that gives equal priority to readers and writers, in the sense that pending readers and writers have an equal chance of being granted access to the resource. Hint: You can solve this problem using a single counting semaphore and a single mutex

```c
#include <stdio.h>
#include <stdlib.h>
#include <pthread.h>
#include <semaphore.h>
#include <unistd.h>

#define N_READERS 5 // Max number of readers
#define NUM_READERS 10
#define NUM_WRITERS 5

sem_t queue;       // Controls access order (fairness)
sem_t resource;    // Controls access to the shared resource
pthread_mutex_t read_mutex = PTHREAD_MUTEX_INITIALIZER;
int read_count = 0;

void *reader(void *arg) {
    int id = *(int *)arg;
    free(arg);

    sem_wait(&queue);             // Wait turn
        pthread_mutex_lock(&read_mutex);
            if (read_count == 0)
                sem_wait(&resource); // First reader locks resource
            read_count++;
        pthread_mutex_unlock(&read_mutex);
    sem_post(&queue);             // Allow next thread

    // Reading section
    printf("Reader %d is reading\n", id);
    sleep(1); // Simulate reading

    pthread_mutex_lock(&read_mutex);
        read_count--;
        if (read_count == 0)
            sem_post(&resource); // Last reader releases resource
    pthread_mutex_unlock(&read_mutex);

    return NULL;
}

void *writer(void *arg) {
    int id = *(int *)arg;
    free(arg);

    sem_wait(&queue);        // Wait turn
        sem_wait(&resource); // Lock resource
    sem_post(&queue);        // Allow next thread

    // Writing section
    printf("Writer %d is writing\n", id);
    sleep(1); // Simulate writing

    sem_post(&resource);     // Release resource

    return NULL;
}

int main() {
    pthread_t r_threads[NUM_READERS], w_threads[NUM_WRITERS];

    // Initialize semaphores
    sem_init(&queue, 0, 1);
    sem_init(&resource, 0, 1);

    // Create reader and writer threads
    for (int i = 0; i < NUM_READERS; i++) {
        int *id = malloc(sizeof(int));
        *id = i + 1;
        pthread_create(&r_threads[i], NULL, reader, id);
    }

    for (int i = 0; i < NUM_WRITERS; i++) {
        int *id = malloc(sizeof(int));
        *id = i + 1;
        pthread_create(&w_threads[i], NULL, writer, id);
    }

    // Join threads
    for (int i = 0; i < NUM_READERS; i++) {
        pthread_join(r_threads[i], NULL);
    }
    for (int i = 0; i < NUM_WRITERS; i++) {
        pthread_join(w_threads[i], NULL);
    }

    // Clean up
    sem_destroy(&queue);
    sem_destroy(&resource);
    pthread_mutex_destroy(&read_mutex);

    return 0;
}
```

📝 Notes:

- `queue` ensures first-come-first-served.

- `resource` enforces exclusive or shared access.

- `read_mutex` protects read_count.

- This example runs 10 readers and 5 writers — you can adjust as needed.

More details:

- `queue` ensures that readers and writers line up in order, and no one skips ahead, which avoids starvation of either readers or writers.

## 👥 Why is queue needed in addition to resource?

Without `queue`, **readers could repeatedly acquire and release `resource` faster than writers**, leading to writer starvation. Writers would be stuck behind a stream of fast readers. (Because reader don't stuck by `resource`, but reader will be stucked when reader/write is running)

So queue makes everyone wait in line to request access:

- Readers acquire the queue lock briefly, then release it quickly after incrementing the read count (so other readers can proceed).

- **why does the reader release `queue` after `read_count++` ?**
  - For `queue` in reader, if `queue` unblocked before `read_count++`, then unleashing `resource` may be impossible if reader quickly rush again(the `resource` in reader will be unlocked only when `read_count == 0`, but now `read_count` increased steadliy). Putting unlock `queue` after `read_count++`, so that when writer waitting in `queue`, new comming reader will be blocked at `queue`, writer will be deal until all before reader finished and at that time `read_count` decreased to 0.

- Writers also wait their turn in the queue, but they hold the `resource` for writing.

This provides fairness: whichever thread gets to the queue first (reader or writer) gets to try acquiring the resource.


## Example

Great! Let’s walk through a **timeline example** with:

- **3 readers**: R1, R2, R3  
- **1 writer**: W1  

Assume:

- All threads arrive **in this order**: R1, R2, W1, R3
- The `queue` semaphore is initialized to **1**
- The `resource` semaphore is also initialized to **1**
- `read_count` is initially **0**

---

### 🧵 Thread Timeline

| Time | Event                                                                 |
|------|-----------------------------------------------------------------------|
| T1   | **R1 arrives**: acquires `queue = 1 → 0`                              |
| T2   | R1 enters critical section: locks `read_mutex`, `read_count = 0 → 1` |
| T3   | Since `read_count == 1`, R1 acquires `resource = 1 → 0`               |
| T4   | R1 releases `queue = 0 → 1`                                           |
| T5   | **R2 arrives**: acquires `queue = 1 → 0`                              |
| T6   | R2 enters critical section: locks `read_mutex`, `read_count = 1 → 2` |
| T7   | Does **not** try to acquire `resource` (already held by R1)          |
| T8   | R2 releases `queue = 0 → 1`                                           |
| T9   | **W1 arrives**: acquires `queue = 1 → 0`                              |
| T10  | W1 tries to acquire `resource` → BLOCKED (held by readers)           |
| T11  | W1 **still holds `queue = 0`**, blocking new arrivals                |
| T12  | **R3 arrives**: blocks on `queue` (value 0)                          |
| T13  | R1 finishes reading: `read_count = 2 → 1`, does not release resource |
| T14  | R2 finishes reading: `read_count = 1 → 0`, releases `resource = 0 → 1`|
| T15  | W1 proceeds: acquires `resource = 1 → 0`, releases `queue = 0 → 1`   |
| T16  | **R3 unblocks**, gets `queue = 1 → 0`, but blocks on `resource`      |
| T17  | W1 finishes writing, releases `resource = 0 → 1`                     |
| T18  | R3 acquires `resource = 1 → 0`, increments `read_count = 0 → 1`      |
| T19  | R3 releases `queue = 0 → 1`                                          |

---

### 🔁 Key Observations

- **R1 and R2 both read concurrently**, no problem.
- **W1 waits patiently** for readers to finish — **but prevents R3 from entering** by holding `queue`.
- **R3 has to wait**, even though `resource` is busy, because **W1 got to `queue` first** — ensuring **fairness**.
- After W1 finishes, **R3 proceeds**, as expected.

---

### 🎯 What This Ensures

- **No starvation**: Writers don’t get endlessly delayed by streams of fast readers.
- **Fairness**: Whoever arrives first gets in first.
- **Concurrency**: Multiple readers still read in parallel when possible.


## Others

**Does with queue means that queue uses a FIFO stack of threads?**

- This is a wrong quesetion, because Stack and queue are two diffrent data structure, and Stack always using LIFO strategy processing data, queue always using FIFO strategy processing data
- The queue in this context doesn’t exactly mean a FIFO stack (or stack-like structure); rather, it refers to a FIFO scheduling mechanism enforced by the semaphore.
- threads either stored in a Queue(FIFO) or a Stack(LIFO). And the user cannot typically decide whether to use a queue or stack for blocked threads in synchronization. The operating system and thread scheduler typically handle this with FIFO queues for fairness.

**❓so when using queue, no matter what order stack that stack use, it can always ensure threads proceed in FIFO, right?**

- Exactly! When using a queue (specifically in the context of a semaphore or thread synchronization), it doesn't matter if the underlying implementation uses a stack or some other data structure internally — the key point is that semaphores enforce FIFO behavior at the logical level.

